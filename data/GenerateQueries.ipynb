{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk insert queries saved to bulk_insert_queries.sql\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = \"PreProcessedData.csv\"  # Replace with your file's path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Sample 500 rows\n",
    "sample_data = data.sample(500, random_state=42)\n",
    "\n",
    "# Extract relevant columns for each table and remove duplicates\n",
    "customers_data = sample_data[['CustomerID', 'InvoiceNo', 'Country']].drop_duplicates()\n",
    "invoice_data = sample_data[['InvoiceNo', 'StockCode', 'InvoiceDate', 'Quantity']].drop_duplicates()\n",
    "stock_data = sample_data[['StockCode', 'Description', 'UnitPrice']].drop_duplicates()\n",
    "\n",
    "# Function to generate bulk insert queries\n",
    "def generate_bulk_insert(table_name, columns, data, unique_column=None):\n",
    "    values = []\n",
    "    unique_values = set()  # To ensure unique values for unique constraints\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        # Handle unique column constraints\n",
    "        if unique_column:\n",
    "            if row[unique_column] in unique_values:\n",
    "                continue  # Skip duplicates\n",
    "            unique_values.add(row[unique_column])\n",
    "        \n",
    "        value_tuple = ', '.join(\n",
    "            [\"'{}'\".format(str(value).replace(\"'\", \"''\")) if isinstance(value, str) else str(value) for value in row]\n",
    "        )\n",
    "        values.append(f\"({value_tuple})\")\n",
    "        \n",
    "    bulk_query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES\\n\" + \",\\n\".join(values) + \";\"\n",
    "    return bulk_query\n",
    "\n",
    "# Generate queries\n",
    "stock_bulk_query = generate_bulk_insert(\n",
    "    \"Stock\", \n",
    "    [\"StockCode\", \"Description\", \"UnitPrice\"], \n",
    "    stock_data,\n",
    "    unique_column=\"StockCode\"  # Ensure unique StockCode\n",
    ")\n",
    "\n",
    "invoice_bulk_query = generate_bulk_insert(\n",
    "    \"Invoice\", \n",
    "    [\"InvoiceNo\", \"StockCode\", \"InvoiceDate\", \"Quantity\"], \n",
    "    invoice_data,\n",
    "    unique_column=\"InvoiceNo\"  # Ensure unique InvoiceNo\n",
    ")\n",
    "\n",
    "customers_bulk_query = generate_bulk_insert(\n",
    "    \"Customers\", \n",
    "    [\"CustomerID\", \"InvoiceNo\", \"Country\"], \n",
    "    customers_data,\n",
    "    unique_column=\"CustomerID\"  # Ensure unique CustomerID\n",
    ")\n",
    "\n",
    "# Save to a file\n",
    "output_file_path = \"bulk_insert_queries.sql\"\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(\"-- Stock Table\\n\")\n",
    "    file.write(stock_bulk_query + \"\\n\\n\")\n",
    "    file.write(\"-- Invoice Table\\n\")\n",
    "    file.write(invoice_bulk_query + \"\\n\\n\")\n",
    "    file.write(\"-- Customers Table\\n\")\n",
    "    file.write(customers_bulk_query + \"\\n\")\n",
    "\n",
    "print(f\"Bulk insert queries saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk insert queries saved to bulk_insert_queries.sql\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "file_path = \"PreProcessedData.csv\"  # Replace with your file's path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract relevant columns for each table and remove duplicates\n",
    "customers_data = data[['CustomerID', 'InvoiceNo', 'Country']].drop_duplicates()\n",
    "invoice_data = data[['InvoiceNo', 'StockCode', 'InvoiceDate', 'Quantity']].drop_duplicates()\n",
    "stock_data = data[['StockCode', 'Description', 'UnitPrice']].drop_duplicates()\n",
    "\n",
    "# Function to generate bulk insert queries\n",
    "def generate_bulk_insert(table_name, columns, data, unique_column=None):\n",
    "    values = []\n",
    "    unique_values = set()  # To ensure unique values for unique constraints\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        # Handle unique column constraints\n",
    "        if unique_column:\n",
    "            if row[unique_column] in unique_values:\n",
    "                continue  # Skip duplicates\n",
    "            unique_values.add(row[unique_column])\n",
    "        \n",
    "        value_tuple = ', '.join(\n",
    "            [\"'{}'\".format(str(value).replace(\"'\", \"''\")) if isinstance(value, str) else str(value) for value in row]\n",
    "        )\n",
    "        values.append(f\"({value_tuple})\")\n",
    "        \n",
    "    bulk_query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES\\n\" + \",\\n\".join(values) + \";\"\n",
    "    return bulk_query\n",
    "\n",
    "# Generate queries\n",
    "stock_bulk_query = generate_bulk_insert(\n",
    "    \"Stock\", \n",
    "    [\"StockCode\", \"Description\", \"UnitPrice\"], \n",
    "    stock_data,\n",
    "    unique_column=\"StockCode\"  # Ensure unique StockCode\n",
    ")\n",
    "\n",
    "invoice_bulk_query = generate_bulk_insert(\n",
    "    \"Invoice\", \n",
    "    [\"InvoiceNo\", \"StockCode\", \"InvoiceDate\", \"Quantity\"], \n",
    "    invoice_data,\n",
    "    unique_column=\"InvoiceNo\"  # Ensure unique InvoiceNo\n",
    ")\n",
    "\n",
    "customers_bulk_query = generate_bulk_insert(\n",
    "    \"Customers\", \n",
    "    [\"CustomerID\", \"InvoiceNo\", \"Country\"], \n",
    "    customers_data,\n",
    "    unique_column=\"CustomerID\"  # Ensure unique CustomerID\n",
    ")\n",
    "\n",
    "# Save to a file\n",
    "output_file_path = \"bulk_insert_queries.sql\"\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(\"-- Stock Table\\n\")\n",
    "    file.write(stock_bulk_query + \"\\n\\n\")\n",
    "    file.write(\"-- Invoice Table\\n\")\n",
    "    file.write(invoice_bulk_query + \"\\n\\n\")\n",
    "    file.write(\"-- Customers Table\\n\")\n",
    "    file.write(customers_bulk_query + \"\\n\")\n",
    "\n",
    "print(f\"Bulk insert queries saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
